//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	triton_
.extern .shared .align 16 .b8 global_smem[];

.visible .entry triton_(
	.param .u64 triton__param_0,
	.param .u64 triton__param_1,
	.param .u64 triton__param_2,
	.param .u64 triton__param_3,
	.param .u64 triton__param_4,
	.param .u64 triton__param_5,
	.param .u64 triton__param_6,
	.param .u32 triton__param_7,
	.param .u32 triton__param_8
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<76>;
	.reg .b32 	%r<164>;
	.reg .f32 	%f<95>;
	.reg .b64 	%rd<58>;
	.reg .f64 	%fd<15>;
	.loc	1 18 0
$L__func_begin0:
	.loc	1 18 0

	ld.param.u64 	%rd35, [triton__param_0];
	ld.param.u64 	%rd36, [triton__param_1];
$L__tmp0:
	.loc	1 21 28
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	.loc	1 21 33
	shl.b32 	%r59, %r1, 5;
	ld.param.u64 	%rd37, [triton__param_2];
	ld.param.u64 	%rd38, [triton__param_3];
	.loc	1 22 44
	mov.u32 	%r60, %tid.x;
	and.b32  	%r61, %r60, 31;
	ld.param.u64 	%rd39, [triton__param_4];
	shl.b32 	%r62, %r60, 2;
	ld.param.u64 	%rd40, [triton__param_5];
	and.b32  	%r63, %r62, 28;
	ld.param.u64 	%rd41, [triton__param_6];
	or.b32  	%r64, %r63, 1;
	ld.param.u32 	%r65, [triton__param_7];
	or.b32  	%r66, %r63, 2;
	or.b32  	%r67, %r63, 3;
	.loc	1 22 23
	or.b32  	%r68, %r59, %r63;
	or.b32  	%r69, %r59, %r64;
	or.b32  	%r70, %r59, %r66;
	or.b32  	%r71, %r59, %r67;
	or.b32  	%r72, %r59, %r61;
	.loc	1 23 21
	setp.lt.s32 	%p1, %r68, %r65;
	setp.lt.s32 	%p2, %r69, %r65;
	setp.lt.s32 	%p3, %r70, %r65;
	setp.lt.s32 	%p4, %r71, %r65;
	setp.lt.s32 	%p45, %r72, %r65;
	.loc	1 27 20
	mul.hi.s32 	%r74, %r68, 799063683;
	shr.u32 	%r75, %r74, 31;
	shr.s32 	%r76, %r74, 5;
	add.s32 	%r77, %r76, %r75;
	mul.hi.s32 	%r79, %r72, 799063683;
	shr.u32 	%r80, %r79, 31;
	shr.s32 	%r81, %r79, 5;
	add.s32 	%r82, %r81, %r80;
	mul.lo.s32 	%r83, %r77, 172;
	sub.s32 	%r84, %r68, %r83;
	.loc	1 29 18
	mul.hi.s32 	%r85, %r69, 799063683;
	shr.u32 	%r86, %r85, 31;
	shr.s32 	%r87, %r85, 5;
	add.s32 	%r88, %r87, %r86;
	mul.lo.s32 	%r89, %r88, 172;
	sub.s32 	%r90, %r69, %r89;
	mul.hi.s32 	%r91, %r70, 799063683;
	shr.u32 	%r92, %r91, 31;
	shr.s32 	%r93, %r91, 5;
	add.s32 	%r94, %r93, %r92;
	mul.lo.s32 	%r95, %r94, 172;
	sub.s32 	%r96, %r70, %r95;
	mul.hi.s32 	%r97, %r71, 799063683;
	shr.u32 	%r98, %r97, 31;
	shr.s32 	%r99, %r97, 5;
	add.s32 	%r100, %r99, %r98;
	mul.lo.s32 	%r101, %r100, 172;
	sub.s32 	%r102, %r71, %r101;
	mul.lo.s32 	%r103, %r82, 172;
	sub.s32 	%r104, %r72, %r103;
	.loc	1 31 30
	mul.wide.s32 	%rd42, %r77, 8;
	add.s64 	%rd2, %rd35, %rd42;
	.loc	1 31 35
	// begin inline asm
	mov.u64 %rd1, 0x0;
	@%p1 ld.global.L1::evict_last.b64 { %rd1 }, [ %rd2 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u64 %rd3, 0x0;
	@%p2 ld.global.L1::evict_last.b64 { %rd3 }, [ %rd2 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u64 %rd5, 0x0;
	@%p3 ld.global.L1::evict_last.b64 { %rd5 }, [ %rd2 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u64 %rd7, 0x0;
	@%p4 ld.global.L1::evict_last.b64 { %rd7 }, [ %rd2 + 0 ];
	// end inline asm
	.loc	1 32 30
	mul.wide.s32 	%rd43, %r77, 4;
	add.s64 	%rd9, %rd36, %rd43;
	.loc	1 32 35
	// begin inline asm
	mov.u32 %r2, 0x0;
	@%p1 ld.global.L1::evict_last.b32 { %r2 }, [ %rd9 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r3, 0x0;
	@%p2 ld.global.L1::evict_last.b32 { %r3 }, [ %rd9 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r4, 0x0;
	@%p3 ld.global.L1::evict_last.b32 { %r4 }, [ %rd9 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r5, 0x0;
	@%p4 ld.global.L1::evict_last.b32 { %r5 }, [ %rd9 + 0 ];
	// end inline asm
	.loc	1 34 31
	mul.wide.s32 	%rd44, %r84, 4;
	add.s64 	%rd21, %rd38, %rd44;
	mul.wide.s32 	%rd45, %r90, 4;
	add.s64 	%rd22, %rd38, %rd45;
	mul.wide.s32 	%rd46, %r96, 4;
	add.s64 	%rd23, %rd38, %rd46;
	mul.wide.s32 	%rd47, %r102, 4;
	add.s64 	%rd24, %rd38, %rd47;
	.loc	1 36 31
	mul.wide.s32 	%rd48, %r82, 4;
	add.s64 	%rd33, %rd40, %rd48;
	.loc	1 24 34
	bfe.u32 	%r105, %r60, 3, 5;
	or.b32  	%r106, %r105, 32;
	.loc	1 26 21
	setp.lt.u32 	%p53, %r106, 50;
	.loc	1 31 35
	mov.b64 	%fd1, %rd1;
	mov.b64 	%fd2, %rd3;
	mov.b64 	%fd3, %rd5;
	mov.b64 	%fd4, %rd7;
	.loc	1 33 41
	mul.lo.s32 	%r107, %r105, 172;
	.loc	1 33 37
	mad.lo.s32 	%r108, %r77, 8600, %r107;
	.loc	1 33 48
	add.s32 	%r109, %r108, %r84;
	add.s32 	%r110, %r108, %r90;
	add.s32 	%r111, %r108, %r96;
	add.s32 	%r112, %r108, %r102;
	.loc	1 33 37
	add.s32 	%r113, %r108, 5504;
	.loc	1 33 48
	add.s32 	%r114, %r113, %r84;
	add.s32 	%r115, %r113, %r90;
	add.s32 	%r116, %r113, %r96;
	add.s32 	%r117, %r113, %r102;
	.loc	1 33 31
	mul.wide.s32 	%rd49, %r109, 4;
	add.s64 	%rd13, %rd37, %rd49;
	mul.wide.s32 	%rd50, %r110, 4;
	add.s64 	%rd14, %rd37, %rd50;
	mul.wide.s32 	%rd51, %r111, 4;
	add.s64 	%rd15, %rd37, %rd51;
	mul.wide.s32 	%rd52, %r112, 4;
	add.s64 	%rd16, %rd37, %rd52;
	mul.wide.s32 	%rd53, %r114, 4;
	add.s64 	%rd17, %rd37, %rd53;
	mul.wide.s32 	%rd54, %r115, 4;
	add.s64 	%rd18, %rd37, %rd54;
	mul.wide.s32 	%rd55, %r116, 4;
	add.s64 	%rd19, %rd37, %rd55;
	mul.wide.s32 	%rd56, %r117, 4;
	add.s64 	%rd20, %rd37, %rd56;
	.loc	1 33 67
	and.pred  	%p17, %p53, %p1;
	and.pred  	%p19, %p53, %p2;
	and.pred  	%p21, %p53, %p3;
	and.pred  	%p23, %p53, %p4;
	mov.b32 	%r7, 0;
	.loc	1 33 59
	// begin inline asm
	mov.u32 %r6, 0x0;
	@%p1 ld.global.b32 { %r6 }, [ %rd13 + 0 ];
	@!%p1 mov.u32 %r6, %r7;
	// end inline asm
	mov.b32 	%f1, %r6;
	// begin inline asm
	mov.u32 %r8, 0x0;
	@%p2 ld.global.b32 { %r8 }, [ %rd14 + 0 ];
	@!%p2 mov.u32 %r8, %r7;
	// end inline asm
	mov.b32 	%f2, %r8;
	// begin inline asm
	mov.u32 %r10, 0x0;
	@%p3 ld.global.b32 { %r10 }, [ %rd15 + 0 ];
	@!%p3 mov.u32 %r10, %r7;
	// end inline asm
	mov.b32 	%f3, %r10;
	// begin inline asm
	mov.u32 %r12, 0x0;
	@%p4 ld.global.b32 { %r12 }, [ %rd16 + 0 ];
	@!%p4 mov.u32 %r12, %r7;
	// end inline asm
	mov.b32 	%f4, %r12;
	// begin inline asm
	mov.u32 %r14, 0x0;
	@%p17 ld.global.b32 { %r14 }, [ %rd17 + 0 ];
	@!%p17 mov.u32 %r14, %r7;
	// end inline asm
	mov.b32 	%f5, %r14;
	// begin inline asm
	mov.u32 %r16, 0x0;
	@%p19 ld.global.b32 { %r16 }, [ %rd18 + 0 ];
	@!%p19 mov.u32 %r16, %r7;
	// end inline asm
	mov.b32 	%f6, %r16;
	// begin inline asm
	mov.u32 %r18, 0x0;
	@%p21 ld.global.b32 { %r18 }, [ %rd19 + 0 ];
	@!%p21 mov.u32 %r18, %r7;
	// end inline asm
	mov.b32 	%f7, %r18;
	// begin inline asm
	mov.u32 %r20, 0x0;
	@%p23 ld.global.b32 { %r20 }, [ %rd20 + 0 ];
	@!%p23 mov.u32 %r20, %r7;
	// end inline asm
	mov.b32 	%f8, %r20;
	.loc	1 34 36
	// begin inline asm
	mov.u32 %r22, 0x0;
	@%p1 ld.global.L1::evict_last.b32 { %r22 }, [ %rd21 + 0 ];
	// end inline asm
	mov.b32 	%f9, %r22;
	// begin inline asm
	mov.u32 %r23, 0x0;
	@%p2 ld.global.L1::evict_last.b32 { %r23 }, [ %rd22 + 0 ];
	// end inline asm
	mov.b32 	%f10, %r23;
	// begin inline asm
	mov.u32 %r24, 0x0;
	@%p3 ld.global.L1::evict_last.b32 { %r24 }, [ %rd23 + 0 ];
	// end inline asm
	mov.b32 	%f11, %r24;
	// begin inline asm
	mov.u32 %r25, 0x0;
	@%p4 ld.global.L1::evict_last.b32 { %r25 }, [ %rd24 + 0 ];
	// end inline asm
	mov.b32 	%f12, %r25;
	.loc	1 35 31
	add.s64 	%rd25, %rd39, %rd49;
	add.s64 	%rd26, %rd39, %rd50;
	add.s64 	%rd27, %rd39, %rd51;
	add.s64 	%rd28, %rd39, %rd52;
	add.s64 	%rd29, %rd39, %rd53;
	add.s64 	%rd30, %rd39, %rd54;
	add.s64 	%rd31, %rd39, %rd55;
	add.s64 	%rd32, %rd39, %rd56;
	.loc	1 35 59
	// begin inline asm
	mov.u32 %r26, 0x0;
	@%p1 ld.global.b32 { %r26 }, [ %rd25 + 0 ];
	@!%p1 mov.u32 %r26, %r7;
	// end inline asm
	mov.b32 	%f13, %r26;
	// begin inline asm
	mov.u32 %r28, 0x0;
	@%p2 ld.global.b32 { %r28 }, [ %rd26 + 0 ];
	@!%p2 mov.u32 %r28, %r7;
	// end inline asm
	mov.b32 	%f14, %r28;
	// begin inline asm
	mov.u32 %r30, 0x0;
	@%p3 ld.global.b32 { %r30 }, [ %rd27 + 0 ];
	@!%p3 mov.u32 %r30, %r7;
	// end inline asm
	mov.b32 	%f15, %r30;
	// begin inline asm
	mov.u32 %r32, 0x0;
	@%p4 ld.global.b32 { %r32 }, [ %rd28 + 0 ];
	@!%p4 mov.u32 %r32, %r7;
	// end inline asm
	mov.b32 	%f16, %r32;
	// begin inline asm
	mov.u32 %r34, 0x0;
	@%p17 ld.global.b32 { %r34 }, [ %rd29 + 0 ];
	@!%p17 mov.u32 %r34, %r7;
	// end inline asm
	mov.b32 	%f17, %r34;
	// begin inline asm
	mov.u32 %r36, 0x0;
	@%p19 ld.global.b32 { %r36 }, [ %rd30 + 0 ];
	@!%p19 mov.u32 %r36, %r7;
	// end inline asm
	mov.b32 	%f18, %r36;
	// begin inline asm
	mov.u32 %r38, 0x0;
	@%p21 ld.global.b32 { %r38 }, [ %rd31 + 0 ];
	@!%p21 mov.u32 %r38, %r7;
	// end inline asm
	mov.b32 	%f19, %r38;
	// begin inline asm
	mov.u32 %r40, 0x0;
	@%p23 ld.global.b32 { %r40 }, [ %rd32 + 0 ];
	@!%p23 mov.u32 %r40, %r7;
	// end inline asm
	mov.b32 	%f20, %r40;
	.loc	1 36 36
	// begin inline asm
	mov.u32 %r57, 0x0;
	@%p45 ld.global.L1::evict_last.b32 { %r57 }, [ %rd33 + 0 ];
	// end inline asm
$L__tmp1:
	.loc	2 74 15
	setp.lt.f64 	%p54, %fd4, 0d4049000000000000;
	setp.lt.f64 	%p55, %fd3, 0d4049000000000000;
	setp.lt.f64 	%p56, %fd2, 0d4049000000000000;
	setp.lt.f64 	%p57, %fd1, 0d4049000000000000;
	.loc	2 76 21
	setp.nan.f64 	%p58, %fd4, %fd4;
	setp.nan.f64 	%p59, %fd3, %fd3;
	setp.nan.f64 	%p60, %fd2, %fd2;
	setp.nan.f64 	%p61, %fd1, %fd1;
	.loc	2 77 29
	selp.f64 	%fd5, %fd1, 0d4049000000000000, %p61;
	selp.f64 	%fd6, %fd1, %fd5, %p57;
	selp.f64 	%fd7, %fd2, 0d4049000000000000, %p60;
	selp.f64 	%fd8, %fd2, %fd7, %p56;
	selp.f64 	%fd9, %fd3, 0d4049000000000000, %p59;
	selp.f64 	%fd10, %fd3, %fd9, %p55;
	selp.f64 	%fd11, %fd4, 0d4049000000000000, %p58;
	selp.f64 	%fd12, %fd4, %fd11, %p54;
	cvt.rn.f64.u32 	%fd13, %r105;
	cvt.rn.f64.u32 	%fd14, %r106;
$L__tmp2:
	.loc	1 41 18
	setp.gt.f64 	%p62, %fd12, %fd14;
	setp.gt.f64 	%p63, %fd10, %fd14;
	setp.gt.f64 	%p64, %fd8, %fd14;
	setp.gt.f64 	%p65, %fd12, %fd13;
	setp.gt.f64 	%p66, %fd10, %fd13;
	setp.gt.f64 	%p67, %fd8, %fd13;
	setp.gt.f64 	%p68, %fd6, %fd14;
	setp.gt.f64 	%p69, %fd6, %fd13;
	.loc	1 43 19
	and.b32  	%r118, %r2, 2147483647;
	setp.eq.s32 	%p70, %r118, 0;
	.loc	1 45 20
	add.f32 	%f21, %f1, %f9;
	add.f32 	%f22, %f2, %f10;
	add.f32 	%f23, %f3, %f11;
	add.f32 	%f24, %f4, %f12;
	add.f32 	%f25, %f5, %f9;
	add.f32 	%f26, %f6, %f10;
	add.f32 	%f27, %f7, %f11;
	add.f32 	%f28, %f8, %f12;
	.loc	1 46 20
	add.f32 	%f29, %f21, %f13;
	add.f32 	%f30, %f22, %f14;
	add.f32 	%f31, %f23, %f15;
	add.f32 	%f32, %f24, %f16;
	add.f32 	%f33, %f25, %f17;
	add.f32 	%f34, %f26, %f18;
	add.f32 	%f35, %f27, %f19;
	add.f32 	%f36, %f28, %f20;
	.loc	1 49 43
	selp.f32 	%f37, %f29, 0f00000000, %p70;
	selp.f32 	%f38, %f29, %f37, %p69;
	selp.f32 	%f39, %f38, 0f00000000, %p1;
	selp.f32 	%f40, %f33, 0f00000000, %p70;
	selp.f32 	%f41, %f33, %f40, %p68;
	selp.f32 	%f42, %f41, 0f00000000, %p17;
$L__tmp3:
	.loc	3 256 15
	add.f32 	%f43, %f39, %f42;
	.loc	3 267 36
	mov.b32 	%r119, %f43;
	shfl.sync.bfly.b32	%r120, %r119, 16, 31, -1;
	mov.b32 	%f44, %r120;
	.loc	3 256 15
	add.f32 	%f45, %f43, %f44;
	.loc	3 267 36
	mov.b32 	%r121, %f45;
	shfl.sync.bfly.b32	%r122, %r121, 8, 31, -1;
	mov.b32 	%f46, %r122;
	.loc	3 256 15
	add.f32 	%f47, %f45, %f46;
	.loc	3 267 36
	setp.lt.u32 	%p46, %r61, 8;
	bfe.u32 	%r123, %r60, 5, 3;
	shl.b32 	%r124, %r123, 2;
	shl.b32 	%r125, %r63, 5;
	or.b32  	%r126, %r125, %r124;
	mov.u32 	%r127, global_smem;
	add.s32 	%r43, %r127, %r126;
	shl.b32 	%r128, %r64, 5;
	or.b32  	%r129, %r128, %r124;
	add.s32 	%r45, %r127, %r129;
	shl.b32 	%r130, %r66, 5;
	or.b32  	%r131, %r130, %r124;
	add.s32 	%r47, %r127, %r131;
	shl.b32 	%r132, %r67, 5;
	or.b32  	%r133, %r132, %r124;
	add.s32 	%r49, %r127, %r133;
	setp.lt.s32 	%p50, %r60, 256;
	add.s32 	%r52, %r127, %r62;
	and.b32  	%r134, %r3, 2147483647;
	and.b32  	%r135, %r4, 2147483647;
	and.b32  	%r136, %r5, 2147483647;
	and.b32  	%r137, %r60, 7;
	setp.eq.s32 	%p71, %r136, 0;
	setp.eq.s32 	%p72, %r135, 0;
	setp.eq.s32 	%p73, %r134, 0;
	setp.eq.s32 	%p74, %r137, 0;
$L__tmp4:
	.loc	1 49 43
	selp.f32 	%f48, %f30, 0f00000000, %p73;
	selp.f32 	%f49, %f30, %f48, %p67;
	selp.f32 	%f50, %f49, 0f00000000, %p2;
	selp.f32 	%f51, %f31, 0f00000000, %p72;
	selp.f32 	%f52, %f31, %f51, %p66;
	selp.f32 	%f53, %f52, 0f00000000, %p3;
	selp.f32 	%f54, %f32, 0f00000000, %p71;
	selp.f32 	%f55, %f32, %f54, %p65;
	selp.f32 	%f56, %f55, 0f00000000, %p4;
	selp.f32 	%f57, %f34, 0f00000000, %p73;
	selp.f32 	%f58, %f34, %f57, %p64;
	selp.f32 	%f59, %f58, 0f00000000, %p19;
	selp.f32 	%f60, %f35, 0f00000000, %p72;
	selp.f32 	%f61, %f35, %f60, %p63;
	selp.f32 	%f62, %f61, 0f00000000, %p21;
	selp.f32 	%f63, %f36, 0f00000000, %p71;
	selp.f32 	%f64, %f36, %f63, %p62;
	selp.f32 	%f65, %f64, 0f00000000, %p23;
$L__tmp5:
	.loc	3 256 15
	add.f32 	%f66, %f50, %f59;
	add.f32 	%f67, %f53, %f62;
	add.f32 	%f68, %f56, %f65;
	.loc	3 267 36
	mov.b32 	%r138, %f66;
	shfl.sync.bfly.b32	%r139, %r138, 16, 31, -1;
	mov.b32 	%f69, %r139;
	.loc	3 256 15
	add.f32 	%f70, %f66, %f69;
	.loc	3 267 36
	mov.b32 	%r140, %f70;
	shfl.sync.bfly.b32	%r141, %r140, 8, 31, -1;
	mov.b32 	%f71, %r141;
	.loc	3 256 15
	add.f32 	%f72, %f70, %f71;
	.loc	3 267 36
	mov.b32 	%r142, %f67;
	shfl.sync.bfly.b32	%r143, %r142, 16, 31, -1;
	mov.b32 	%f73, %r143;
	.loc	3 256 15
	add.f32 	%f74, %f67, %f73;
	.loc	3 267 36
	mov.b32 	%r144, %f74;
	shfl.sync.bfly.b32	%r145, %r144, 8, 31, -1;
	mov.b32 	%f75, %r145;
	.loc	3 256 15
	add.f32 	%f76, %f74, %f75;
	.loc	3 267 36
	mov.b32 	%r146, %f68;
	shfl.sync.bfly.b32	%r147, %r146, 16, 31, -1;
	mov.b32 	%f77, %r147;
	.loc	3 256 15
	add.f32 	%f78, %f68, %f77;
	.loc	3 267 36
	mov.b32 	%r148, %f78;
	shfl.sync.bfly.b32	%r149, %r148, 8, 31, -1;
	mov.b32 	%f79, %r149;
	.loc	3 256 15
	add.f32 	%f80, %f78, %f79;
	.loc	3 267 36
	mov.b32 	%r44, %f47;
	// begin inline asm
	@%p46 st.shared.b32 [ %r43 + 0 ], %r44;
	// end inline asm
	mov.b32 	%r46, %f72;
	// begin inline asm
	@%p46 st.shared.b32 [ %r45 + 0 ], %r46;
	// end inline asm
	mov.b32 	%r48, %f76;
	// begin inline asm
	@%p46 st.shared.b32 [ %r47 + 0 ], %r48;
	// end inline asm
	mov.b32 	%r50, %f80;
	// begin inline asm
	@%p46 st.shared.b32 [ %r49 + 0 ], %r50;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p50 ld.shared.b32 %r51, [ %r52 + 0 ];
	// end inline asm
	mov.b32 	%f81, %r51;
	shfl.sync.bfly.b32	%r150, %r51, 4, 31, -1;
	mov.b32 	%f82, %r150;
	.loc	3 256 15
	add.f32 	%f83, %f81, %f82;
	.loc	3 267 36
	mov.b32 	%r151, %f83;
	shfl.sync.bfly.b32	%r152, %r151, 2, 31, -1;
	mov.b32 	%f84, %r152;
	.loc	3 256 15
	add.f32 	%f85, %f83, %f84;
	.loc	3 267 36
	mov.b32 	%r153, %f85;
	shfl.sync.bfly.b32	%r154, %r153, 1, 31, -1;
	mov.b32 	%f86, %r154;
	.loc	3 256 15
	add.f32 	%f87, %f85, %f86;
	.loc	3 267 36
	and.pred  	%p51, %p50, %p74;
	mov.b32 	%r54, %f87;
	// begin inline asm
	@%p51 st.shared.b32 [ %r52 + 0 ], %r54;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r155, %r127, %r125;
	ld.shared.f32 	%f88, [%r155];
	add.s32 	%r156, %r127, %r128;
	ld.shared.f32 	%f89, [%r156];
	add.s32 	%r157, %r127, %r130;
	ld.shared.f32 	%f90, [%r157];
	add.s32 	%r158, %r127, %r132;
	ld.shared.f32 	%f91, [%r158];
$L__tmp6:
	.loc	1 53 20
	bar.sync 	0;
	shl.b32 	%r159, %r137, 4;
	add.s32 	%r160, %r127, %r159;
	st.shared.v4.f32 	[%r160], {%f88, %f89, %f90, %f91};
	bar.sync 	0;
	shl.b32 	%r161, %r61, 2;
	add.s32 	%r162, %r127, %r161;
	ld.shared.f32 	%f92, [%r162];
	mov.b32 	%r56, 1065353216;
	.loc	1 52 20
	// begin inline asm
	div.full.f32 %r55, %r56, %r57;
	// end inline asm
	mov.b32 	%f93, %r55;
	.loc	1 53 20
	mul.f32 	%f94, %f92, %f93;
	.loc	1 54 31
	mad.lo.s32 	%r163, %r82, 1872, %r104;
	.loc	1 54 25
	mul.wide.s32 	%rd57, %r163, 4;
	add.s64 	%rd34, %rd41, %rd57;
	.loc	1 54 49
	setp.eq.s32 	%p75, %r123, 0;
	mov.b32 	%r58, %f94;
	and.pred  	%p52, %p75, %p45;
	// begin inline asm
	@%p52 st.global.b32 [ %rd34 + 0 ], { %r58 };
	// end inline asm
	.loc	1 54 4
	ret;
$L__tmp7:
$L__func_end0:

}
	.file	1 "/home/admin/zy429782/fx_experiments/torch_aot_tool/dynamicLib_7622_gpu_torch260/r2/cr2bzfsu7zlnmu74s6vf5fnysuwuhxgpcom7tsaz4267anppe7np.py"
	.file	2 "/home/admin/zy429782/miniforge3/envs/torch_preview_0924/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py"
	.file	3 "/home/admin/zy429782/miniforge3/envs/torch_preview_0924/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 257
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 114
.b8 50
.b8 98
.b8 122
.b8 102
.b8 115
.b8 117
.b8 55
.b8 122
.b8 108
.b8 110
.b8 109
.b8 117
.b8 55
.b8 52
.b8 115
.b8 54
.b8 118
.b8 102
.b8 53
.b8 102
.b8 110
.b8 121
.b8 115
.b8 117
.b8 119
.b8 117
.b8 104
.b8 120
.b8 103
.b8 112
.b8 99
.b8 111
.b8 109
.b8 55
.b8 116
.b8 115
.b8 97
.b8 122
.b8 52
.b8 50
.b8 54
.b8 55
.b8 97
.b8 110
.b8 112
.b8 112
.b8 101
.b8 55
.b8 110
.b8 112
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 97
.b8 100
.b8 109
.b8 105
.b8 110
.b8 47
.b8 122
.b8 121
.b8 52
.b8 50
.b8 57
.b8 55
.b8 56
.b8 50
.b8 47
.b8 102
.b8 120
.b8 95
.b8 101
.b8 120
.b8 112
.b8 101
.b8 114
.b8 105
.b8 109
.b8 101
.b8 110
.b8 116
.b8 115
.b8 47
.b8 116
.b8 111
.b8 114
.b8 99
.b8 104
.b8 95
.b8 97
.b8 111
.b8 116
.b8 95
.b8 116
.b8 111
.b8 111
.b8 108
.b8 47
.b8 100
.b8 121
.b8 110
.b8 97
.b8 109
.b8 105
.b8 99
.b8 76
.b8 105
.b8 98
.b8 95
.b8 55
.b8 54
.b8 50
.b8 50
.b8 95
.b8 103
.b8 112
.b8 117
.b8 95
.b8 116
.b8 111
.b8 114
.b8 99
.b8 104
.b8 50
.b8 54
.b8 48
.b8 47
.b8 114
.b8 50
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 180
.b8 4
.b32 180
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 38
.b8 40
.b8 4
.b32 180
.b64 $L__tmp3
.b64 $L__tmp6
.b8 1
.b8 50
.b8 26
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
